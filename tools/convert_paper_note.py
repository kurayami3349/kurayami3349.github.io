# SPDX-License-Identifier: MIT 
# Copyright (c) 2025 qq7r. All rights reserved.
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Usage:
  python tools/convert_paper_note.py path/to/input_note.md title \
    --date YYYY-MM-DD [--output-dir output_dir] [--image-base-url /assets/img] \
    [--images-output-dir path/to/copy/images]

è¯¥è„šæœ¬å°†åŸå§‹ Markdown ç¬”è®°è½¬æ¢ä¸º Jekyll åšå®¢æ–‡ç« æ ¼å¼ï¼Œå¹¶å¯é€‰åœ°è§„èŒƒä¸é‡å†™å›¾ç‰‡å¼•ç”¨ã€‚
åŒæ—¶ä¼šåœ¨å†…å®¹ä¸­è‡ªåŠ¨æå– arXiv idï¼Œå¹¶å°†å…¶ä½œä¸ºå›¾ç‰‡ç®¡ç†é”®ç”¨äºï¼š
- å¤åˆ¶å›¾ç‰‡åˆ° `images_output_dir/arxiv-<id>/filename`
- å°†ç›¸å¯¹å›¾ç‰‡é“¾æ¥é‡å†™ä¸º `image_base_url/arxiv-<id>/filename`
"""

import os
import re
from datetime import datetime
import argparse
import shutil
from typing import Optional
import urllib.request
import urllib.error

root_dir = os.path.dirname(os.path.dirname(__file__))


class PaperNoteConverter:
  """å°†åŸå§‹ Markdown ç¬”è®°è½¬æ¢ä¸º Jekyll åšæ–‡çš„è½¬æ¢å™¨ã€‚
  åŠŸèƒ½ï¼š
  - ç”Ÿæˆå¸¦ front matter çš„æ–‡ç« å†…å®¹
  - å¤„ç†å¹¶è§„èŒƒå›¾ç‰‡å¼•ç”¨ï¼ˆMarkdown ä¸ HTML ä¸¤ç§å½¢å¼ï¼‰
  - ä»å†…å®¹ä¸­æå– arXiv id ä½œä¸ºå›¾ç‰‡ç®¡ç†é”®
  - ç”Ÿæˆç›®æ ‡æ–‡ä»¶
  """

  def __init__(self, image_base_url: Optional[str] = "/img"):
    """åˆå§‹åŒ–è½¬æ¢å™¨ã€‚
    å‚æ•°:
      image_base_url (Optional[str]): å›¾ç‰‡åŸºç¡€ URL å‰ç¼€ï¼Œæœªæä¾›æ—¶é»˜è®¤ä½¿ç”¨ "/img"ã€‚
    """
    # é¡¹ç›®æ ¹ç›®å½•é»˜è®¤å–ä¸ºå½“å‰è„šæœ¬ä¸Šçº§çš„ä¸Šçº§ç›®å½•
    self.root_dir = root_dir
    self.image_base_url = image_base_url or "/img"

  def create_front_matter(self, title: str, date: str) -> str:
    """åˆ›å»º Jekyll æ–‡ç« çš„ front matterã€‚
    å‚æ•°:
      title (str): æ–‡ç« æ ‡é¢˜ã€‚
      date (str): å‘å¸ƒæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ã€‚
    è¿”å›:
      str: front matter å­—ç¬¦ä¸²ã€‚
    """
    return f"""---
title: {title}
date: {date}
categories: [è®ºæ–‡ç¬”è®°]
tags: [å¾…è®¾ç½®]
description: å¾…æ·»åŠ æ–‡ç« æè¿°
---

{{% include paper_note_style.html %}}

<div class=\"paper-note-container\" markdown=\"1\">
"""

  def process_content(self, content: str) -> str:
    """å¤„ç† Markdown å†…å®¹ï¼Œæ·»åŠ å¿…è¦çš„ç»“æ„å’Œæç¤ºã€‚
    å‚æ•°:
      content (str): åŸå§‹ Markdown å†…å®¹ã€‚
    è¿”å›:
      str: å¤„ç†åçš„å†…å®¹ã€‚
    """
    content = content.lstrip()

    pdf_comment = """<!--
è¦åµŒå…¥PDFï¼Œè¯·åœ¨Meta Dataéƒ¨åˆ†åæ·»åŠ ä»¥ä¸‹ä»£ç ï¼š
{% include pdf_embed.html file=\"path/to/your/paper.pdf\" id=\"unique-id\" %}
-->
"""

    meta_data_pos = content.find("### Meta Data")
    meta_data_end = content.find("***", meta_data_pos) if meta_data_pos != -1 else -1
    if meta_data_end != -1:
      content = content[:meta_data_end] + "\n" + pdf_comment + content[meta_data_end:]

    content = content.rstrip() + "\n\n</div>"
    return content

  def arxiv_abs_exists(self, arxiv_id: str, timeout: float = 5.0) -> bool:
    """éªŒè¯ arXiv abs é¡µé¢æ˜¯å¦å­˜åœ¨ã€‚
    å‚æ•°:
      arxiv_id (str): å½¢å¦‚ '2504.18829' æˆ–åŒ…å«ç‰ˆæœ¬ '2504.18829v2' çš„ arXiv idã€‚
      timeout (float): è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
    è¿”å›:
      bool: é¡µé¢æ˜¯å¦å­˜åœ¨ã€‚
    """
    url = f"https://arxiv.org/abs/{arxiv_id}"
    req = urllib.request.Request(url, headers={"User-Agent": "PaperNoteConverter/1.0", "Accept": "text/html"})
    try:
      with urllib.request.urlopen(req, timeout=timeout) as resp:
        return 200 <= getattr(resp, "status", 200) < 400
    except urllib.error.HTTPError as e:
      # 404 æ˜ç¡®ä¸å­˜åœ¨ï¼›å…¶ä»–é”™è¯¯è§†ä¸ºä¸å¯ç”¨
      return 200 <= e.code < 400
    except Exception:
      return False

  def extract_arxiv_key(self, content: str) -> Optional[str]:
    """ä»å†…å®¹ä¸­æå– arXiv idï¼Œå¹¶è¿”å›ç”¨äºå›¾ç‰‡ç®¡ç†çš„é”®ã€‚
    æ”¯æŒæ ¼å¼ç¤ºä¾‹ï¼š
      "**ArXiv id:** arXiv:2504.18829"ã€"arXiv:2401.12345v2"ï¼Œæˆ– URL å½¢å¼ "https://arxiv.org/abs/2504.18829"ã€‚
    è¿”å›ç¤ºä¾‹ï¼š
      "arxiv-2504.18829" æˆ– "arxiv-2401.12345v2"ã€‚

    å‚æ•°:
      content (str): åŸå§‹ Markdown å†…å®¹ã€‚
    è¿”å›:
      Optional[str]: è§„èŒƒåŒ–åçš„å›¾ç‰‡ç®¡ç†é”®ï¼Œæœªæ‰¾åˆ°åˆ™ä¸º Noneã€‚
    """
    # 1) ç›´æ¥çš„ "arXiv:..." å†™æ³•ï¼Œå‰ç½®è¯è¾¹ç•Œ
    m = re.search(r"(?i)\barxiv:\s*([0-9]{4}\.[0-9]{4,5}(?:v\d+)?)", content)
    if not m:
      # 2) "ArXiv id: arXiv:..." å†™æ³•
      m = re.search(r"(?i)arxiv\s*id\s*[:ï¼š]\s*arxiv:\s*([0-9]{4}\.[0-9]{4,5}(?:v\d+)?)", content)
    if not m:
      # 3) URL å†™æ³•
      m = re.search(r"(?i)https?://arxiv\.org/abs/([0-9]{4}\.[0-9]{4,5}(?:v\d+)?)", content)
    if not m:
      return None

    arxiv_id = m.group(1)

    # å…ˆæ£€æŸ¥å®Œæ•´ idï¼ˆå¯èƒ½åŒ…å«ç‰ˆæœ¬ï¼‰
    if self.arxiv_abs_exists(arxiv_id):
      return f"arxiv-{arxiv_id}"

    # è‹¥åŒ…å«ç‰ˆæœ¬ä¸”ä¸å­˜åœ¨ï¼Œå°è¯•å»æ‰ç‰ˆæœ¬é‡æ–°æ£€æŸ¥
    base_id = re.sub(r"v\d+$", "", arxiv_id)
    if base_id != arxiv_id and self.arxiv_abs_exists(base_id):
      print(f"âš ï¸ æœªæ‰¾åˆ° arXiv é¡µé¢ï¼š{arxiv_id}ï¼Œæ”¹ç”¨ {base_id}")
      return f"arxiv-{base_id}"

    print(f"âš ï¸ æœªæ‰¾åˆ° arXiv é¡µé¢ï¼š{arxiv_id}ï¼Œä¸ä½¿ç”¨å›¾ç‰‡åˆ†ç»„é”®")
    return None

  def process_images(
    self,
    content: str,
    input_dir: Optional[str] = None,
    image_base_url: Optional[str] = None,
    copy_to_dir: Optional[str] = None,
    image_key: Optional[str] = None,
  ) -> str:
    """å¤„ç† Markdown ä¸ HTML ä¸­çš„å›¾ç‰‡å¼•ç”¨ã€‚
    è¡Œä¸ºï¼š
    - è¯†åˆ«å¹¶å¤„ç† `![alt](src)` ä¸ `<img src=\"src\">` ä¸¤ç§æ ¼å¼ï¼›
    - å¯¹ç›¸å¯¹è·¯å¾„å›¾ç‰‡ï¼šå¦‚æä¾› `image_base_url` åˆ™é‡å†™ä¸ºç«™ç‚¹å†…è·¯å¾„ï¼ˆå¯åœ¨å…¶åé™„åŠ  `image_key` å­ç›®å½•ï¼‰ï¼›
      å¦‚æä¾› `copy_to_dir` åˆ™å¤åˆ¶å›¾ç‰‡åˆ°è¯¥ç›®å½•ï¼ˆå¦‚æœ‰ `image_key` åˆ™å¤åˆ¶åˆ°å…¶å­ç›®å½•ï¼‰å¹¶ä¿ç•™æ–‡ä»¶åï¼›
    - å¯¹ä»¥ `http://`ã€`https://`ã€`/` å¼€å¤´çš„ç»å¯¹é“¾æ¥ä¿æŒä¸å˜ã€‚
    - ç»Ÿä¸€å›¾ç‰‡çš„ alt æ–‡æœ¬ä¸ºé¡ºåºç¼–å·ï¼šfig1, fig2, ...ï¼ˆæŒ‰å‡ºç°é¡ºåºï¼‰ã€‚

    å‚æ•°:
      content (str): åŸå§‹ Markdown å†…å®¹ã€‚
      input_dir (Optional[str]): è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œç”¨äºè§£æç›¸å¯¹è·¯å¾„å›¾ç‰‡æºæ–‡ä»¶ã€‚
      image_base_url (Optional[str]): ç«™ç‚¹å†…å›¾ç‰‡åŸºç¡€ URL å‰ç¼€ï¼ˆå¦‚ `/img`ï¼‰ï¼Œæœªä¼ æ—¶ä¼šä½¿ç”¨ç±»é»˜è®¤å€¼ã€‚
      copy_to_dir (Optional[str]): å¤åˆ¶ç›¸å¯¹è·¯å¾„å›¾ç‰‡åˆ°è¯¥ç›®å½•ï¼ˆå¯é€‰ï¼‰ã€‚
      image_key (Optional[str]): å›¾ç‰‡ç®¡ç†é”®ï¼ˆå¦‚åŸºäº arXiv idï¼‰ï¼Œç”¨äºå­ç›®å½•ã€‚
    è¿”å›:
      str: å·²é‡å†™å›¾ç‰‡é“¾æ¥çš„å†…å®¹ã€‚
    """
    def is_relative(src: str) -> bool:
      return not (src.startswith("http://") or src.startswith("https://") or src.startswith("/"))

    def rewrite_src(src: str) -> str:
      # å¤åˆ¶åˆ°æŒ‡å®šç›®å½•ï¼ˆå¯é€‰ä¸”ä»…å¤„ç†ç›¸å¯¹è·¯å¾„ï¼‰
      if copy_to_dir and input_dir and is_relative(src):
        try:
          target_dir = copy_to_dir if not image_key else os.path.join(copy_to_dir, image_key)
          os.makedirs(target_dir, exist_ok=True)
          src_abs = os.path.normpath(os.path.join(input_dir, src))
          if os.path.isfile(src_abs):
            shutil.copy2(src_abs, os.path.join(target_dir, os.path.basename(src)))
        except Exception:
          # è‹¥å¤åˆ¶å¤±è´¥ï¼Œä¸å½±å“è½¬æ¢æµç¨‹ï¼Œä»…ä¿ç•™åŸé“¾æ¥æˆ–é‡å†™é“¾æ¥
          pass

      # é‡å†™é“¾æ¥åˆ°ç«™ç‚¹è·¯å¾„ï¼ˆä¿ç•™æ–‡ä»¶åï¼‰
      if image_base_url and is_relative(src):
        base = image_base_url.rstrip('/')
        if image_key:
          return f"{base}/{image_key}/{os.path.basename(src)}"
        return f"{base}/{os.path.basename(src)}"
      return src

    # ç»Ÿä¸€ alt çš„é¡ºåºè®¡æ•°å™¨
    fig_counter = 1

    # å¤„ç† Markdown å›¾ç‰‡ï¼š![alt](src)
    pattern_md = re.compile(r"!\[([^\]]*)\]\(([^)\s]+)(?:\s+\"[^\"]*\")?\)")

    def repl_md(match: re.Match) -> str:
      nonlocal fig_counter
      src = match.group(2)
      new_src = rewrite_src(src)
      alt_text = f"fig{fig_counter}"
      fig_counter += 1
      return f"![{alt_text}]({new_src})"

    content = pattern_md.sub(repl_md, content)

    # å¤„ç† HTML å›¾ç‰‡ï¼š<img ... src=\"...\" ...>
    pattern_html = re.compile(r"<img([^>]*)src=\"([^\"]+)\"([^>]*)>")

    def set_alt(attrs: str, alt_text: str) -> str:
      # æ›¿æ¢å·²å­˜åœ¨çš„ altï¼Œæˆ–æ’å…¥ä¸€ä¸ªæ–°çš„ alt
      if re.search(r"\balt\s*=\s*\"", attrs):
        return re.sub(r"\balt\s*=\s*\"[^\"]*\"", f"alt=\"{alt_text}\"", attrs)
      # æ’å…¥åˆ°å±æ€§å¼€å¤´ï¼Œä¿æŒç®€å•å¯é 
      return f" alt=\"{alt_text}\"{attrs}"

    def repl_html(match: re.Match) -> str:
      nonlocal fig_counter
      pre = match.group(1)
      src = match.group(2)
      post = match.group(3)
      new_src = rewrite_src(src)
      alt_text = f"fig{fig_counter}"
      fig_counter += 1
      attrs = f"{pre}src=\"{new_src}\"{post}"
      attrs = set_alt(attrs, alt_text)
      return f"<img{attrs}>"

    content = pattern_html.sub(repl_html, content)
    return content

  def convert_note(
    self,
    input_file: str,
    title: str,
    date: str,
    output_dir: Optional[str] = None,
    image_base_url: Optional[str] = None,
    images_output_dir: Optional[str] = None,
  ) -> bool:
    """è½¬æ¢ç¬”è®°æ–‡ä»¶ä¸º Jekyll æ ¼å¼å¹¶å¯é€‰å¤„ç†å›¾ç‰‡ã€‚
    å‚æ•°:
      input_file (str): è¾“å…¥ Markdown æ–‡ä»¶è·¯å¾„ã€‚
      title (str): æ–‡ç« æ ‡é¢˜ã€‚
      date (str): å‘å¸ƒæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ã€‚
      output_dir (Optional[str]): æ–‡ç« è¾“å‡ºç›®å½•ï¼ˆæœªæä¾›æ—¶é»˜è®¤ `root_dir/_posts`ï¼‰ã€‚
      image_base_url (Optional[str]): å›¾ç‰‡ç«™ç‚¹å‰ç¼€ï¼ˆç›¸å¯¹è·¯å¾„é‡å†™ç”¨ï¼Œæœªæä¾›æ—¶ä½¿ç”¨ç±»çš„é»˜è®¤ "/img"ï¼‰ã€‚
      images_output_dir (Optional[str]): å¤åˆ¶ç›¸å¯¹å›¾ç‰‡åˆ°è¯¥ç›®å½•ï¼ˆæœªæä¾›æ—¶é»˜è®¤ `root_dir/img`ï¼‰ã€‚
    è¿”å›:
      bool: è½¬æ¢æ˜¯å¦æˆåŠŸã€‚
    """
    try:
      if not os.path.exists(input_file):
        print(f"\nâŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_file}")
        return False

      with open(input_file, "r", encoding="utf-8") as f:
        content = f.read()

      # ä»å†…å®¹æå– arXiv id ä½œä¸ºå›¾ç‰‡ç®¡ç†é”®
      image_key = self.extract_arxiv_key(content)

      input_dir = os.path.dirname(input_file)
      # è®¾å®šæœ‰æ•ˆçš„åŸºç¡€ URLã€å¤åˆ¶ç›®å½•ä¸è¾“å‡ºç›®å½•
      effective_base_url = image_base_url if image_base_url is not None else self.image_base_url
      effective_copy_dir = images_output_dir if images_output_dir is not None else os.path.join(self.root_dir, "img")
      effective_output_dir = output_dir if output_dir is not None else os.path.join(self.root_dir, "_posts")

      content = self.process_images(
        content,
        input_dir=input_dir,
        image_base_url=effective_base_url,
        copy_to_dir=effective_copy_dir,
        image_key=image_key,
      )

      processed_content = self.process_content(content)
      full_content = self.create_front_matter(title, date) + processed_content

      # éªŒè¯æ—¥æœŸæ ¼å¼
      _ = datetime.strptime(date, "%Y-%m-%d")

      os.makedirs(effective_output_dir, exist_ok=True)
      file_name = f"{date}-{title.lower().replace(' ', '-')}.md"
      output_file = os.path.join(effective_output_dir, file_name)

      with open(output_file, "w", encoding="utf-8") as f:
        f.write(full_content)

      print("\nâœ… ç¬”è®°è½¬æ¢æˆåŠŸï¼")
      print(f"ğŸ“ æ–°æ–‡ä»¶å·²åˆ›å»ºï¼š{output_file}")
      print("\nâš ï¸ è¯·æ³¨æ„ï¼š")
      print("1. è®¾ç½®åˆé€‚çš„æ–‡ç« æ ‡ç­¾ (tags)")
      print("2. æ·»åŠ æ–‡ç« æè¿° (description)")
      print("3. å¦‚éœ€åµŒå…¥PDFï¼Œè¯·æŒ‰æ–‡ä»¶ä¸­çš„æ³¨é‡Šè¯´æ˜æ·»åŠ PDFåµŒå…¥ä»£ç ")
      print("4. æ£€æŸ¥å¹¶è°ƒæ•´æ–‡ç« çš„æ ¼å¼å’Œå†…å®¹")
      print("5. è‹¥ä½¿ç”¨äº†å›¾ç‰‡é‡å†™æˆ–å¤åˆ¶ï¼Œè¯·æ ¸å¯¹å›¾ç‰‡æ˜¯å¦æ­£ç¡®æ˜¾ç¤º")
      if image_key:
        print(f"6. æœ¬æ–‡å›¾ç‰‡å·²æŒ‰é”®åˆ†ç»„ï¼š{image_key}")
      return True
    except Exception as e:
      print(f"\nâŒ è½¬æ¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
      return False


def main():
  """å‘½ä»¤è¡Œå…¥å£ï¼šè§£æå‚æ•°å¹¶æ‰§è¡Œè½¬æ¢ã€‚"""
  parser = argparse.ArgumentParser(description="å°†åŸå§‹Markdownç¬”è®°è½¬æ¢ä¸ºJekyllåšå®¢æ ¼å¼ï¼Œå¹¶å¤„ç†å›¾ç‰‡å¼•ç”¨")
  parser.add_argument("input_file", help="è¾“å…¥çš„Markdownæ–‡ä»¶è·¯å¾„")
  parser.add_argument("title", help="æ–‡ç« æ ‡é¢˜")
  parser.add_argument("--date", help="å‘å¸ƒæ—¥æœŸ (YYYY-MM-DDæ ¼å¼)", default=datetime.now().strftime("%Y-%m-%d"))
  parser.add_argument("--output-dir", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ root_dir/_postsï¼‰", default=None)
  parser.add_argument("--image-base-url", help="å›¾ç‰‡åŸºç¡€URLå‰ç¼€ï¼ˆç”¨äºé‡å†™ç›¸å¯¹è·¯å¾„ï¼Œé»˜è®¤ /imgï¼‰", default=None)
  parser.add_argument("--images-output-dir", help="å¤åˆ¶ç›¸å¯¹å›¾ç‰‡åˆ°è¯¥ç›®å½•ï¼ˆé»˜è®¤ root_dir/imgï¼‰", default=None)

  args = parser.parse_args()

  converter = PaperNoteConverter()
  success = converter.convert_note(
    input_file=args.input_file,
    title=args.title,
    date=args.date,
    output_dir=args.output_dir,
    image_base_url=args.image_base_url,
    images_output_dir=args.images_output_dir,
  )

  if success:
    print("\nğŸ‰ è½¬æ¢å®Œæˆï¼è¯·æ£€æŸ¥æ–°ç”Ÿæˆçš„æ–‡ä»¶å¹¶è¿›è¡Œå¿…è¦çš„è°ƒæ•´ã€‚")
  else:
    print("\nâŒ è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•ã€‚")


if __name__ == "__main__":
  main()