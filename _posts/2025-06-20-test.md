---
title: TITLE
date: 2025-06-20 +/-0800
categories: [TOP_CATEGORY, SUB_CATEGORY]
tags: [TAG]     # TAG names should always be lowercase
author: sss01
description: Short summary of the post.
---




{% include pdf_embed.html file="https://arxiv.org/pdf/2504.18829" id="unique-id" %}

# Note

Comment: Accepted by Robotics: Science and Systems (RSS 2025)

project website: (<https://pku-epic.github.io/Dexonomy/>)

### Meta Data

*   **Title:** Dexonomy: synthesizing all dexterous grasp types in a grasp taxonomy (2025-04-26)

*   **Author:** Jiayi Chen; Lin Peng; He Wang

*   **ArXiv id:** arXiv:2504.18829

*   **DOI:** [10.48550/arXiv.2504.18829](https://doi.org/10.48550/arXiv.2504.18829)

*   **URL:** <https://arxiv.org/abs/2504.18829>

*   **Local Link:** [Chen 等 - 2025 - Dexonomy Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy.pdf](zotero://open-pdf/0_U5H3JU46)

*   **Abstract:**\
    Generalizable dexterous grasping with suitable grasp types is a fundamental skill for intelligent robots. Developing such skills requires a large-scale and high-quality dataset that covers numerous grasp types (i.e., at least those categorized by the GRASP taxonomy), but collecting such data is extremely challenging. Existing automatic grasp synthesis methods are often limited to specific grasp types or object categories, hindering scalability. This work proposes an efficient pipeline capable of synthesizing contact-rich, penetration-free, and physically plausible grasps for any grasp type, object, and articulated hand. Starting from a single human-annotated template for each hand and grasp type, our pipeline tackles the complicated synthesis problem with two stages: optimize the object to fit the hand template first, and then locally refine the hand to fit the object in simulation. To validate the synthesized grasps, we introduce a contact-aware control strategy that allows the hand to apply the appropriate force at each contact point to the object. Those validated grasps can also be used as new grasp templates to facilitate future synthesis. Experiments show that our method significantly outperforms previous type-unaware grasp synthesis baselines in simulation. Using our algorithm, we construct a dataset containing 10.7k objects and 9.5M grasps, covering 31 grasp types in the GRASP taxonomy. Finally, we train a type-conditional generative model that successfully performs the desired grasp type from single-view object point clouds, achieving an 82.3% success rate in real-world experiments. Project page: https\://pku-epic.github.io/Dexonomy.

*   **Research Tags:**

    *   Computer Science - Computer Vision and Pattern Recognition
    *   Computer Science - Robotics

***



### **1. 研究背景与动机**

*   **研究背景**：\
    灵巧抓取（Dexterous Grasping）是机器人灵活操作环境的基础能力，但现有研究多关注“能否抓取”而非“如何抓取”，导致灵巧手的功能被简化为平行夹爪。GRASP分类法定义了33种人类抓取类型，但现有数据驱动方法受限于高质量数据集的稀缺性。当前数据集或仅支持少数抓取类型（如指尖抓取），或依赖耗时的人类示教（如遥操作）\[1,47]。
*   **研究动机**：\
    作者提出两个核心挑战：(1) **类型感知抓取生成**（如何为指定类型的物体生成高质量抓取姿态）；(2) **可扩展数据集构建**（如何自动化生成覆盖多种抓取类型的大规模数据）。这些问题限制了机器人执行任务导向的灵巧操作能力\[20,47]。

***

### **2. 创新贡献**

1.  **高效抓取合成框架**：提出两阶段优化流水线（全局物体位姿对齐+局部手部姿态微调），支持从单个人工标注模板扩展到任意物体和抓取类型\[图2]。
2.  **大规模数据集**：构建包含9.5M抓取姿态和10.7k物体的数据集Dexonomy，覆盖GRASP分类法中31种抓取类型\[表I]。
3.  **物理验证策略**：提出基于接触感知的控制方法，通过MuJoCo仿真验证抓取的力闭合性\[IV-D节]。
4.  **类型条件生成模型**：实现从单视角点云生成指定类型的抓取姿态，真实实验成功率82.3%\[VI节]。

***

### **3. 研究方法**

#### **模型架构**

![\<img alt="" data-attachment-key="VZRTYBYT" width="1425" height="597" src="attachments/VZRTYBYT.png" ztype="zimage"> | 1425](attachments/VZRTYBYT.png)

*   **双阶段流水线**：\
    (1) **全局对齐**：在GPU上并行优化物体位姿（缩放/旋转/平移）以匹配模板接触点\[Eq.7]；<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2F4jjwpaNF%2Fitems%2F65L4FSWN%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/65L4FSWN">Chen 等, 2025, p. 4</a></span>)</span> 🔤优化处理后，通过四项标准筛选结果：

    *   首先，最终能量函数值必须**低于阈值**，以确保手部与物体接触点良好匹配；
    *   其次，需避免手部与物体间的严重穿透现象，我们采用基于线段参数化的**手部碰撞骨架检测**方法进行高效识别（详见附录A）；
    *   第三，由公式6计算的物体接触质量评分需超过预设阈值；
    *   最后，我们实施类**最远点采样**的流程以筛除重复的物体位姿变换，具体方法见附录A。🔤

    (2) **局部微调**：基于MuJoCo的雅可比转置控制调整手部关节角度，实现毫米级接触精度\[Eq.8]。

*   **模板迭代扩展**：成功抓取会被自动加入模板库，减少人工标注需求\[IV-E节]。

#### **算法设计**

*   **关键差异**：传统方法直接优化手部位姿易陷入局部最优，本文先优化物体位姿再微调手部，提升成功率的同时保持姿态自然性\[IV节]。
*   **仿真验证**：通过六方向外力测试抓取稳定性，设计QP问题求解最优接触力分布\[Eq.3]。

#### **数据处理**

*   **数据来源**：5,697个物体来自DexGraspNet\[47]，5,000个来自Objaverse\[18]。
*   **预处理**：使用CoACD进行凸分解，OpenVDB移除内部面，ACVD简化网格\[附录B]。

***

### **4. 实验设计与结果**

#### **实验设置**

*   **硬件**：8×NVIDIA RTX 3090 GPUs + 2×Intel Xeon Platinum 8255C CPUs。
*   **基线方法**：DexGraspNet\[47]、FRoGGeR\[25]、SpringGrasp\[8]、BODex\[7]。
*   **指标**：抓取成功率（GSR）、物体成功率（OSR）、接触链接数（CLN）、穿透深度（PD）等\[VII-A节]。

#### **对比实验结果**

*   **类型无关抓取合成**：在Allegro手上，本文GSR达60.5%，显著优于基线（BODex为49.2%），且接触更丰富（CLN=4.38 vs 3.85）\[表II]。
*   **类型感知抓取**：对于剪刀等物体，本文方法接触点数量（10个）远超功能抓取迁移方法\[图6]。

#### **消融实验**

*   **模块重要性**：移除模板库更新使GSR下降19%\[表V]；接触感知控制策略提升功率抓取成功率7%\[表VI]。
*   **鲁棒性验证**：即使初始模板噪声较大，模板迭代策略仍能保持高成功率\[表VII]。

***

### **5. 相关工作**

*   **分析型抓取合成**：传统方法依赖力闭合指标，难以生成多样化抓取类型\[21,40]。
*   **功能抓取迁移**：LHFG\[48]等方法受限于几何相似物体，本文支持任意物体\[III-B节]。
*   **仿真优化**：不同于自定义能量函数的方法\[47,7]，本文利用MuJoCo原生物理引擎实现高效微调\[III-D节]。

***

### **6. 总结与启示**

#### **工作总览**

本文提出Dexonomy框架，通过几何匹配和物理仿真相结合，解决了类型感知灵巧抓取生成的难题。其核心创新包括两阶段优化流水线和接触感知控制策略，构建了迄今最全面的灵巧抓取数据集，并验证了类型条件生成模型在真实场景的有效性。

#### **领域启示**

*   **方法论**：证明从少量人工标注出发，通过仿真优化可规模化合成高质量抓取数据。
*   **应用**：首次实现覆盖GRASP分类法的通用抓取生成，支持任务导向的机器人操作。
*   **局限性**：静态抓取假设可能限制动态操作场景，未来需结合强化学习\[57]。

#### **批判性思考**

*   **仿真与现实差距**：Shadow手的欠驱动机制在仿真中未完全建模，影响部署效果\[附录E]。
*   **多样性限制**：某些抓取类型（如侧握）因物体适配性问题成功率偏低\[表IV]。
